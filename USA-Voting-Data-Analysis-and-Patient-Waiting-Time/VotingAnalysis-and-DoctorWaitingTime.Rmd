---
title: "Project_Vivek_Chauhan"
author: "Vivek_Chauhan"
date: "April 8, 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

loading required libraries

```{r package, include=FALSE}
library(dplyr)
library(tidyr)
library(haven)
library(forcats)
library(fastDummies)
library(glmnet)
library(foreign)
library(ggplot2)
library(ggrepel)
library(gridExtra)
```
Setting seed and display options

```{r seed}
set.seed(500)
options(scipen = 100, digits = 4)
```

# Section 1 : R programming competition [Moderate]:

* In statistics, a Poisson distribution is a probability distribution that is used to show how many times an event is likely to occur over a specified period. In other words, it is a count distribution. 
* Poisson distributions are often used to understand independent events that occur at a constant rate within a given interval of time.[1]

```{r doctor}
## 1. a.
#We don't have an upper bound on patients that would be arriving at the clinic, so we may use of poisson distribution 
#clinic_time = (16 - 9)*60 =420
upper_bound_approximation <- qpois(0.999999, 42)
# we round upper_bound_approximation to 100
# expected_arrive <- 10
# count_of_patients <- clinic_time / expected_arrive
# lambda <- 1/expected_arrive

# function that is able to draw n random numbers from exponential distribution with given lambda
# we are calculating the patients that arrive in clinic in 420 minutes
#exponential distribution draws 100 random number converts its vector o/p to a tibble storing time and cummulative sum of time and finally return time list where time less than 420
p_arrival_func <- function(lambda, t, n=100) {
  rexp(n, lambda) %>% 
    tibble(
      delay = .,
      time = cumsum(delay)
    ) %>% 
    filter(time <= t) %>% 
    pull(time) %>% 
    return()
}

lambda <- 1 / 10 
#clinic_time :total time open in a day
t <- (16 - 9) * 60

p_arrival_func(lambda, t)

# creating a function that keeps track of appointments, waiting time and patients that waited
appointment_func <- function(p_arrival_func, t=0) {
  
  p_waited <- 0         # number of patients who have had to wait so far
  total_waiting_time <- 0     # total waiting time so far
  doctors_time <- c(0, 0, 0) # next time at which each doctor is free to see another patient
  
  #when a patient arrives it is attended by available doctor which is tracked in doctors_time list
  #wait time is added to total waited time if pateient arrival time and time when doctor is vailable
  #appointment time is a uniform distribution , so appointment end time is a sum of start and uniform number from given distribution
  for(i in (1:length(p_arrival_func))) {
    wait <- pmax(min(doctors_time) - p_arrival_func[i], 0) # waiting time of patient i
    total_waiting_time <- total_waiting_time + wait
    p_waited <- p_waited + (wait > 0)
    a_start <- max(c(min(doctors_time), p_arrival_func[i]))
    a_end <- a_start + runif(1, 5, 20)
    doctors_time[which.min(doctors_time)] <- a_end
  }
  #summarizing the variables tracked so far in a list and reurn list
  list(
    number_patients = length(p_arrival_func),
    patients_waited = p_waited,
    #total_waiting_time = total_waiting_time,
    #total_waiting_time_per_patient = total_waiting_time / length(p_arrival_func),
    total_waiting_time_per_waiting_patient = total_waiting_time / p_waited,
    closing_time = pmax(max(doctors_time), t)
  ) %>% return()
  
}

#stdout to console the varibales for part1
var_list<-p_arrival_func(lambda, t) %>% 
  appointment_func(t)
print("Variable are : ")
print(var_list)

## b. 
#function to simulate the appointment func 1000 times, replicate method used to repeat the expiremnet
simulation_func <- function(iters, lambda, t, n=100) {
  iters %>% 
    replicate(appointment_func(p_arrival_func(lambda, t, n), t)) %>% 
    t() %>% 
    as_tibble() %>% 
    mutate_all(unlist)
}
#Calling the function
s <- simulation_func(1000, lambda, t)
s
#Summarising the variable returned by simulation func for 1000 iterations
number_of_patients_waited<-round(mean(s$number_patients),0)
patients_waited<-mean(s$patients_waited)
total_waiting_time_per_waiting_patient<-mean(s$total_waiting_time_per_waiting_patient, na.rm=TRUE)
closing_time <- mean(s$closing_time)
print(paste("Mean of number of patients for 1000 simulation:",number_of_patients_waited))
print(paste("Mean of patients waited : ",patients_waited))
print(paste("Mean of total time waited per waiting patient",total_waiting_time_per_waiting_patient))
print(paste("Closing time of clinic :",closing_time))
#plotting to visualize the normal aand exponential nature
par(mfrow=c(2,2))
hist(s$number_patients,col = "red")
hist(s$patients_waited, col="blue")
hist(s$total_waiting_time_per_waiting_patient, col="green")
hist(s$closing_time,col="brown")

```

### References :

[1] Received from URL https://www.r-tutor.com/elementary-statistics/probability-distributions/poisson-distribution
[2] Received from URL https://jpreszler.rbind.io/post/2019-09-09-poisson-simulation/



## Section 2: Data Analysis Questions [Difficult]


```{r Data_Analysis}

# 1. 

## a.
Q1Data1 <- read.dta("C:/Users/hp/Desktop/Winter_22/MSCI_718/Project/Final_Project/Q1Data1.dta")


## a. 1)
colnames1 <- c("state","marital","heat2","heat4")  
state_leave <- c("alaska","hawaii","washington dc")
df1 <- subset(Q1Data1, !(state %in% state_leave), select = colnames1)

## a.2)
df1$heat2 <- ifelse(is.na(df1$heat2),as.character(df1$heat4) , as.character(df1$heat2))
#df1$heat2<-as.factor(df1$heat2)
df2 <- subset(df1, !(heat2 == 'NA' & heat4 == 'NA'))

## a. 3)
heat2_cond <- c("dem/lean dem", "rep/lean rep")
df3 <- filter(df2, heat2 %in% heat2_cond) 

## a. 4)
df3$marital <- factor( x = df3$marital, exclude = NULL, 
                       levels = c("missing/not asked","married","divorced","separated","widowed",
                                  "never married","living with a partner" ,"dk/refused"),
                       labels = c("other", "married","other","other","other","other","other","other"))
df3$state <- droplevels(df3$state)
df3<-df3[!is.na(df3$marital),]
#dim(df3)


## b.
table.state.heat2 <- table(df3$state, df3$heat2)


## b. 1) 
df3.state.dem_lean <- df3 %>%
  group_by(state) %>%
  mutate(Total_per_state = n()) %>% 
  filter(heat2 == "dem/lean dem") %>%
  group_by(state,Total_per_state) %>%
  summarise(n = n()) %>%
  mutate(freq = n / Total_per_state)
df3.state.dem_lean

## b. 2)
df3.state.marital <- df3 %>%
  group_by(state) %>%
  mutate(Total_per_state = n()) %>%
  filter(marital == "married") %>% 
  group_by(state,Total_per_state) %>%
  summarise(n = n()) %>%
  mutate(freq = n / Total_per_state)
df3.state.marital

## b. 3)
df3.state.dem.married <- df3 %>% 
  group_by(state) %>% 
  filter(marital == "married") %>%
  mutate(Total_married_per_state = n()) %>% 
  group_by(state, heat2,Total_married_per_state) %>% 
  summarise(N = n()) %>% 
  mutate(Ratio = round(N/Total_married_per_state, 2)) %>%
  filter(heat2 == "dem/lean dem")
df3.state.dem.married

## b. 4)
df3.state.dem.unmarried <- df3 %>% 
  group_by(state) %>% 
  filter(marital == "other") %>%
  mutate(Total_unmarried_per_state = n()) %>% 
  group_by(state, heat2,Total_unmarried_per_state) %>% 
  summarise(N = n()) %>% 
  mutate(Ratio = round(N/Total_unmarried_per_state, 2)) %>%
  filter(heat2 == "dem/lean dem")
df3.state.dem.unmarried

## b.5)
diff_col <- c("state","Ratio")
df3.state.dem.married.filter <- subset(df3.state.dem.married, select = diff_col)
df3.state.dem.unmarried.filter <- subset(df3.state.dem.unmarried, select = diff_col)

df3.state.dem.filter.join= df3.state.dem.married.filter %>% 
  inner_join(df3.state.dem.unmarried.filter, by= "state")

df3.state.dem.filter.join$difference <- df3.state.dem.filter.join[,2] - df3.state.dem.filter.join[,3]
colnames(df3.state.dem.filter.join)[2] <- "Ratio(Married)"
colnames(df3.state.dem.filter.join)[3] <- "Ratio(Unmarried)"

df3.state.dem.filter.join$difference <- df3.state.dem.filter.join$difference *100
#colnames(df3.state.dem.filter.join)[4] <- "Percentage Difference in Ratios"
head(df3.state.dem.filter.join, 5)



## c.
Q1Data2 <- read.csv("C:/Users/hp/Desktop/Winter_22/MSCI_718/Project/Final_Project/Q1Data2.csv",header = T, stringsAsFactors = F)
df.data2 = as_factor(Q1Data2)
colnames2 <- c("state" ,"vote_Obama_pct")
state_leave <- c("Alaska","Hawaii","District of Columbia")
df1.data2 <- subset(df.data2, !(state %in% state_leave), select = colnames2)
head(df1.data2, 5)


## d.

df3$heat2 <- factor(df3$heat2, levels = c("rep/lean rep","dem/lean dem"), labels = c(0,1))
glm_outcome <- df3$heat2
glm_predictor <- model.matrix(heat2 ~ marital + state, data = df3, family ="binomial")

#assumption -1
glm_predictor_1<- model.matrix(heat2 ~ marital, data = df3, family ="binomial")
model_complete_pooling <- glmnet(x = glm_predictor_1, y = glm_outcome, 
                                 alpha = 0, lambda = 0, family ="binomial")
coef(model_complete_pooling)
y_predicted_complete_pooling <- predict(model_complete_pooling, s = 0, newx = glm_predictor_1,family ="binomial", type = "response" )

#assumption -2

glm_predictor_2 <- model.matrix(heat2 ~ marital + state + state:marital , data = df3, family ="binomial")

model_no_pooling <- glmnet(x = glm_predictor_2, y = glm_outcome, alpha = 0, 
                           lambda = 0, family ="binomial")
coef(model_no_pooling)
y_predicted_no_pooling <- predict(model_no_pooling, s = 0, newx = glm_predictor_2,family ="binomial", type = "response" )


#Assumption-3

glm_predictor_3 <- model.matrix(heat2 ~ marital + state + state:marital , data = df3, family ="binomial")
#assumption :we need to use the penalized regression
# p_fac <- rep(1, ncol(glm_predictor_3))
# p_fac[2] <- 0
# cv_model_ridge <- cv.glmnet(x = glm_predictor_3, y = glm_outcome, 
#                             alpha = 0,penalty.factor = p_fac,family ="binomial")
# #plot(cv_model_ridge)
# best_lambda_ridge <- cv_model_ridge$lambda.min
# 
# 
# model_ridge <- glmnet(x = glm_predictor_3, y = glm_outcome, alpha = 0, lambda =
#                         best_lambda_ridge ,family ="binomial")
# coef(model_ridge)
# y_predicted_ridge <- predict(model_ridge, s = best_lambda_ridge,
#                                  newx = glm_predictor_3,family ="binomial" , type = "response")

##without using the penalty
cv_model_ridge <- cv.glmnet(x = glm_predictor_3, y = glm_outcome,
                            alpha = 0,family ="binomial")
#plot(cv_model_ridge)
best_lambda_ridge <- cv_model_ridge$lambda.min


model_ridge <- glmnet(x = glm_predictor_3, y = glm_outcome, alpha = 0, lambda =
                        best_lambda_ridge ,family ="binomial")
coef(model_ridge)
y_predicted_ridge <- predict(model_ridge, s = best_lambda_ridge,
                                 newx = glm_predictor_3,family ="binomial" , type = "response")
## e.

df1.data2$vote_Obama_pct<- df1.data2$vote_Obama_pct / 100


plot_df <-data.frame(df3$state, y_predicted_ridge)
predicted_vote_share_by_state<-plot_df %>% 
  group_by(df3.state) %>%
  summarise_at(vars(s1), list(mean = mean))

# ggplot(df1.data2, aes(x=state, y=vote_Obama_pct)) +
#   geom_point(shape=0, fill="red", color="blue", size=3) +
#   geom_label_repel(aes(label = df1.data2$state),size = 3.5) +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))+
#   geom_point(data =predicted_vote_share_by_state , 
#              mapping = aes(x = df3.state,
#                            y = mean),shape=23, fill="blue", color="red", size=3 )+
#   geom_text(aes(x = df3.state,
#                 y = mean),label=df1.data2$state, data = predicted_vote_share_by_state)


par(mfrow=c(1,2)) 
plot(df3.state.dem_lean$freq,df1.data2$vote_Obama_pct,sub="Actual vote intention vs Obama vote percent", #sub="Actual vote intention vs Obama vote percent",
  xlab="Democratic vote intention", ylab="Obama vote pct")
text(df3.state.dem_lean$freq, df1.data2$vote_Obama_pct, df1.data2$state, pch=19, col="red")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 

plot(predicted_vote_share_by_state$mean,df1.data2$vote_Obama_pct,sub ="Predicted vote intention vs Obama vote percent",
  xlab="Democratic vote intention", ylab="Obama vote pct")
text(predicted_vote_share_by_state$mean, df1.data2$vote_Obama_pct, df1.data2$state, col="blue", bg="red")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 

## f.


# cv_model_ridge_marriage_gap <- cv.glmnet(x = glm_predictor, y = glm_outcome, 
#                             alpha = 0,family ="binomial")
# #plot(cv_model_ridge)
# best_lambda_ridge_marriage_gap <- cv_model_ridge_marriage_gap$lambda.min
# 
# 
# model_ridge_marriage_gap <- glmnet(x = glm_predictor, y = glm_outcome, alpha = 0, lambda =
#                                      best_lambda_ridge_marriage_gap ,family ="binomial")
# coef(model_ridge_marriage_gap)

# y_predicted_ridge_marraige_gap <- predict(model_ridge_marriage_gap, s = best_lambda_ridge,
#                              newx = glm_predictor,family ="binomial", type = "response" )

glm_predictor_f <- model.matrix(heat2 ~ marital + state + state:marital + 0 , data = df3, family ="binomial")
cv_model_ridge_marriage_gap <- cv.glmnet(x = glm_predictor_f, y = glm_outcome,
                            alpha = 0,family ="binomial")
#plot(cv_model_ridge)
best_lambda_ridge_marriage_gap <- cv_model_ridge_marriage_gap$lambda.min
model_marriage_gap <- glmnet(x = glm_predictor_f, y = glm_outcome, 
                                 alpha = 0, lambda = best_lambda_ridge_marriage_gap, family ="binomial")
coef(model_marriage_gap)
y_predicted_ridge_marraige_gap <- predict(model_marriage_gap, s = 0, newx = glm_predictor_f,family ="binomial", type = "response" )#, type = "response"


plot_df_marriage_gap <-data.frame(df3$state, y_predicted_ridge_marraige_gap)
predicted_vote_share_by_state_marriage_gap<-plot_df_marriage_gap %>% 
  group_by(df3.state) %>%
  summarise_at(vars(s1), list(mean = mean))


par(mfrow=c(1,2)) 
plot(df3.state.dem.filter.join$difference$Ratio.x/100,df1.data2$vote_Obama_pct,sub="Actual  marriage gap vs Obama vote percent",
  xlab="Actual marriage gap", ylab="Obama vote pct")
text(df3.state.dem.filter.join$difference$Ratio.x/100, df1.data2$vote_Obama_pct, df1.data2$state, pch=19, col="blue")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 

plot(predicted_vote_share_by_state_marriage_gap$mean,df1.data2$vote_Obama_pct,sub="Predicted marriage gap vs Obama vote percent",
  xlab="Predicted marriage gap", ylab="Obama vote pct")
text(predicted_vote_share_by_state_marriage_gap$mean, df1.data2$vote_Obama_pct, df1.data2$state, col="brown")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 



## g. 1)

plot_df <-data.frame(df3$state, y_predicted_complete_pooling)
predicted_vote_share_by_state<-plot_df %>%
  group_by(df3.state) %>%
  summarise_at(vars(s1), list(mean = mean))


par(mfrow=c(1,2)) 
plot(df3.state.dem_lean$freq,df1.data2$vote_Obama_pct,sub="Actual vote intention vs Obama vote percent",
  xlab="Democratic vote intention", ylab="Obama vote pct")
text(df3.state.dem_lean$freq, df1.data2$vote_Obama_pct, df1.data2$state, pch=15, col="blue")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 

plot(predicted_vote_share_by_state$mean,df1.data2$vote_Obama_pct,sub ="Predicted vote intention vs Obama vote percent",
  xlab="Democratic vote intention", ylab="Obama vote pct")
text(predicted_vote_share_by_state$mean, df1.data2$vote_Obama_pct, df1.data2$state, col="red")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 

## g. 2)

y_predicted_complete_pooling <- predict(model_complete_pooling, s = 0, newx = glm_predictor_1,family ="binomial" , type = "response")#, type = "response"

plot_df_marriage_gap <-data.frame(df3$state, y_predicted_complete_pooling)
predicted_vote_share_by_state_marriage_gap<-plot_df_marriage_gap %>% 
  group_by(df3.state) %>%
  summarise_at(vars(s1), list(mean = mean))


par(mfrow=c(1,2)) 
plot(df3.state.dem.filter.join$difference$Ratio.x/100,df1.data2$vote_Obama_pct,sub="Actual  marriage gap vs Obama vote percent",
  xlab="Actual marriage gap", ylab="Obama vote pct")
text(df3.state.dem.filter.join$difference$Ratio.x/100, df1.data2$vote_Obama_pct, df1.data2$state, pch=19, col="blue")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 

plot(predicted_vote_share_by_state_marriage_gap$mean,df1.data2$vote_Obama_pct,sub="Predicted marriage gap vs Obama vote percent",
  xlab="Predicted marriage gap", ylab="Obama vote pct")
text(predicted_vote_share_by_state_marriage_gap$mean, df1.data2$vote_Obama_pct, df1.data2$state, col="brown")
grid (NULL,NULL, lty = 6, col = "cornsilk2") 
```

* We observe that when plotted with assumption 1 (i.e, no state heterogenity) , the predicted values for intention to vote for democratic supporters are less spread comapred with assumption 3 where we penalize weigts which are far from mean using ridge regularizer.
* When plotted for marriage gap ,we observed that the results were similar and no major were deviationis observed.

* When these results were compared against assumption 2, we observed significant difference and model with a regularizer performed well at task of prediction.



